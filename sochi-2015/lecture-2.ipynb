{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture-2\n",
    "\n",
    "##### Ivan Oseledets, Skolkovo Institute of Science and Technology \n",
    "##### oseledets.github.io, i.oseledets@skoltech.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Previous lecture \n",
    "- Tensors are a natural model for multivariate probability distributions\n",
    "- Can be used to compute expectations, quantiles, solve stochastic PDEs\n",
    "- Tensor decompositions are needed to reduce the curse of dimensionality\n",
    "- Goal: is to beat Monte-Carlo by using **low-rank** structure\n",
    "- In order to build tensor decompositions, we need to know about matrix methods\n",
    "- Standard tensor decomposition are difficult to be used numerically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today lecture\n",
    "- Basic properties of the tensor trains\n",
    "- Basic problems & algorithms\n",
    "- Application to path integrals (integration over Brownian motion)\n",
    "- Application to financial integrals\n",
    "- Graphical models\n",
    "- (If time permits) Demo of Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensor-train\n",
    "Tensor-train (in physics known as matrix-product-state) representation has the form\n",
    "\n",
    "$$\n",
    "   A(i_1, \\ldots, i_d) = G_1(i_1) \\ldots G_d(i_d), \n",
    "$$\n",
    "where $G_k(i_k)$ has size $r_{k-1} \\times r_k$ and $r_0 = r_d = 1$. \n",
    "\n",
    "Now we have **d-1** ranks (we call them TT-ranks). The parametrization is defined by **TT-cores**.\n",
    "\n",
    "Why tensor train? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TT-ranks are matrix ranks\n",
    " Define unfoldings: \n",
    " \n",
    " $A_k = A(i_1 \\ldots i_k; i_{k+1} \\ldots i_d)$, $n^k \\times n^{d-k}$\n",
    " matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   Theorem: there exists a TT-decomposition with TT-ranks  \n",
    "   \n",
    "   $$r_k = \\mathrm{rank} A_k$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The proof \n",
    "Proof is simple and give the TT-SVD algorithm (in quantum information it is known as Vidal algorithm).\n",
    "\n",
    "Let us do it on the whiteboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stability estimate\n",
    "No exact ranks in practice -- stability estimate! \n",
    "\n",
    "If $A_k = R_k + E_k$, $||E_k|| = \\varepsilon_k$\n",
    "  $$||\\mathbf{A}-\\mathbf{TT}||_F \\leq \\sqrt{\\sum_{k=1}^{d-1} \\varepsilon^2_k}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fast and trivial linear algebra\n",
    " Addition, Hadamard product, scalar product, convolution \n",
    " \n",
    " All scale linear in $d$ \n",
    " \n",
    " $$C(i_1,\\ldots,i_d) = A(i_1,\\ldots,i_d) B(i_1,\\ldots,i_d)$$\n",
    "    \n",
    "   $$C_k(i_k) = A_k(i_k) \\otimes B_k(i_k),$$\n",
    "   ranks are multiplied\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rounding\n",
    "**Rounding** procedure solves the following problem: given a TT-representation\n",
    "\n",
    "$$A(i_1, \\ldots, i_d) = G_1(i_1) G_2(i_2) \\ldots G_d(i_d)$$\n",
    "\n",
    "find **another one** with smaller memory that approximates it with **threshold** $\\epsilon$.\n",
    "\n",
    "It can be done in $\\mathcal{O}(dnr^3)$ operations using the **linear structure** of the format:\n",
    "\n",
    "We can do orthogonalization of the cores! (whiteboard again)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross approximation in $d$-dimensions\n",
    "\n",
    "Oseledets, Tyrtyshnikov, TT-cross approximation of multidimensional arrays, which generalizes the matrix result.\n",
    "\n",
    "**Theorem:** A rank-$r$ tensor can be recovered from $\\mathcal{O}(dnr^2)$ elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantized tensor-train\n",
    "To used tensor decompositions, we have to **approximate** a continious problem by a discrete, where the **vector of unknowns** can be indexed by a $d$-index.\n",
    "\n",
    "1. (Standard) Given a function of $d$ variables, introduce a tensor-product basis set, and the tensor is the tensor of coefficients\n",
    "2. (Non-standard) Given a function of one variable, take it on a uniform grid with $2^d$ points, reshape into a $2 \\times \\ldots \\times 2$ $d$-dimensional tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantized tensor train\n",
    "\n",
    "It is a mapping from 1D functions to $d$-dimensional arrays, using the following representation:\n",
    "\n",
    "$$v_k = f(x_k), \\quad k = 1, \\ldots, 2^d.$$\n",
    "\n",
    "$V(i_1, \\ldots, i_d) = v(a + i h)$, $\\quad i = i_1 + 2 i_2 + \\ldots 2^{d-1} i_d.$\n",
    "\n",
    "It gives $\\mathcal{O}(2dr^2) = \\mathcal{O}(\\log N)$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Representation of some basic functions\n",
    "Almost all important functions in 1D are of low QTT-ranks\n",
    "\n",
    "- $f(x) = \\exp(\\lambda x)$ -- rank $1$\n",
    "- $f(x) = \\sin( w x + \\alpha)$ -- rank $2$\n",
    "- $f(x)$ -- polynomial, rank $p+1$\n",
    "- Rational functions, even non-smooth functions (Weirstrass function has bounded QTT-ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us do some demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=multifuncrs= sweep 1{2}, max_dy: 1.353e+01, erank: 5.83095\n",
      "=multifuncrs= sweep 2{1}, max_dy: 1.006e-13, erank: 6.55744\n",
      "This is a 70-dimensional tensor \n",
      "r(0)=1, n(0)=2 \n",
      "r(1)=1, n(1)=2 \n",
      "r(2)=1, n(2)=2 \n",
      "r(3)=1, n(3)=2 \n",
      "r(4)=1, n(4)=2 \n",
      "r(5)=1, n(5)=2 \n",
      "r(6)=1, n(6)=2 \n",
      "r(7)=1, n(7)=2 \n",
      "r(8)=1, n(8)=2 \n",
      "r(9)=1, n(9)=2 \n",
      "r(10)=1, n(10)=2 \n",
      "r(11)=1, n(11)=2 \n",
      "r(12)=1, n(12)=2 \n",
      "r(13)=1, n(13)=2 \n",
      "r(14)=1, n(14)=2 \n",
      "r(15)=1, n(15)=2 \n",
      "r(16)=1, n(16)=2 \n",
      "r(17)=1, n(17)=2 \n",
      "r(18)=1, n(18)=2 \n",
      "r(19)=1, n(19)=2 \n",
      "r(20)=1, n(20)=2 \n",
      "r(21)=2, n(21)=2 \n",
      "r(22)=2, n(22)=2 \n",
      "r(23)=2, n(23)=2 \n",
      "r(24)=2, n(24)=2 \n",
      "r(25)=2, n(25)=2 \n",
      "r(26)=2, n(26)=2 \n",
      "r(27)=2, n(27)=2 \n",
      "r(28)=2, n(28)=2 \n",
      "r(29)=2, n(29)=2 \n",
      "r(30)=2, n(30)=2 \n",
      "r(31)=2, n(31)=2 \n",
      "r(32)=2, n(32)=2 \n",
      "r(33)=2, n(33)=2 \n",
      "r(34)=2, n(34)=2 \n",
      "r(35)=2, n(35)=2 \n",
      "r(36)=2, n(36)=2 \n",
      "r(37)=2, n(37)=2 \n",
      "r(38)=2, n(38)=2 \n",
      "r(39)=2, n(39)=2 \n",
      "r(40)=2, n(40)=2 \n",
      "r(41)=2, n(41)=2 \n",
      "r(42)=2, n(42)=2 \n",
      "r(43)=2, n(43)=2 \n",
      "r(44)=2, n(44)=2 \n",
      "r(45)=2, n(45)=2 \n",
      "r(46)=2, n(46)=2 \n",
      "r(47)=2, n(47)=2 \n",
      "r(48)=2, n(48)=2 \n",
      "r(49)=2, n(49)=2 \n",
      "r(50)=2, n(50)=2 \n",
      "r(51)=2, n(51)=2 \n",
      "r(52)=2, n(52)=2 \n",
      "r(53)=2, n(53)=2 \n",
      "r(54)=2, n(54)=2 \n",
      "r(55)=2, n(55)=2 \n",
      "r(56)=2, n(56)=2 \n",
      "r(57)=2, n(57)=2 \n",
      "r(58)=2, n(58)=2 \n",
      "r(59)=2, n(59)=2 \n",
      "r(60)=2, n(60)=2 \n",
      "r(61)=2, n(61)=2 \n",
      "r(62)=2, n(62)=2 \n",
      "r(63)=2, n(63)=2 \n",
      "r(64)=2, n(64)=2 \n",
      "r(65)=2, n(65)=2 \n",
      "r(66)=2, n(66)=2 \n",
      "r(67)=2, n(67)=2 \n",
      "r(68)=2, n(68)=2 \n",
      "r(69)=2, n(69)=2 \n",
      "r(70)=1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tt\n",
    "fun = lambda x: np.sin(20*x)\n",
    "a = 0\n",
    "b = 20\n",
    "d = 70\n",
    "N = 2 ** d\n",
    "h = (b - a)*1.0/(N + 1)\n",
    "t = tt.xfun(2, d) * h\n",
    "eps = 1e-12\n",
    "s1 = tt.multifuncrs2([t], fun, eps)\n",
    "s1 = s1.round(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More complicated integral\n",
    "\n",
    "Consider the integral \n",
    "\n",
    "$$\\int^{\\infty}_0 \\frac{\\sin x}{x} dx = \\frac{\\pi}{2}.$$\n",
    "\n",
    "Let us compute with rectangular rule on a finite interval $[0, b]$.\n",
    "\n",
    "We take $2^d$ points, and use **cross approximation** to compute the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=multifuncrs= sweep 1{2}, max_dy: 2.613e+01, erank: 5.74456\n",
      "=multifuncrs= sweep 2{1}, max_dy: 5.046e-03, erank: 8.77496\n",
      "=multifuncrs= sweep 2{2}, max_dy: 5.046e-03, erank: 10.247\n",
      "=multifuncrs= sweep 3{1}, max_dy: 5.657e-12, erank: 11.8322\n",
      "=multifuncrs= sweep 3{2}, max_dy: 5.657e-12, erank: 11.7047\n",
      "=multifuncrs= sweep 4{1}, max_dy: 9.912e-14, erank: 11.8743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-9.3675221912725704e-07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "fun = lambda x: np.sin(x)/x\n",
    "a = 0\n",
    "b = 1e6\n",
    "d = 60\n",
    "N = 2 ** d\n",
    "h = (b - a)*1.0/(N - 1)\n",
    "e = tt.ones(2, d)\n",
    "t = (tt.xfun(2, d) + e)* h \n",
    "eps = 1e-12\n",
    "s1 = tt.multifuncrs2([t], fun, eps)\n",
    "tt.dot(s1, e) * h - math.pi/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Path integrals\n",
    "In this paper we focus on the one-dimensional reaction-diffusion equation\n",
    "with initial distribution $f(x): \\mathbb{R} \\to \\mathbb{R}^{+}$\n",
    "and a constant diffusion coefficient~$\\sigma$\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    " & \\frac{\\partial}{\\partial t} u(x,t)\n",
    " = \\sigma \\frac{\\partial^2}{\\partial x^2} u(x,t) - V(x,t) u(x,t),\\\\\n",
    "& u(x,0)=f(x)\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\qquad t \\in [0, T],\n",
    "\\quad x \\in \\mathbb{R}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feyman-Kac formula\n",
    "The solution can be expressed by the Feynman-Kac\n",
    "formula\n",
    "\\begin{equation}\n",
    "u_{f}(x,T)=\\int_{\\mathcal C\\{x,0; T \\}}  f(\\xi(T))\n",
    " e^{-\\int_{0}^{T}\\! V(\\xi(\\tau),T-\\tau) d\\tau }\n",
    "\\mathcal{D}_{\\xi},\n",
    "\\end{equation}\n",
    "where the integration is done over a set of all\n",
    "continuous paths $\\xi(T): [0,T]\\to \\mathbb{R}$\n",
    "from the Banach space $\\Xi([0,T], \\mathbb{R})$\n",
    "starting at $\\xi(0)=x$ and stopping at arbitrary endpoints at time $T$.\n",
    "$\\mathcal{D}_{\\xi}$ is the Wiener measure,\n",
    "and $\\xi(t)$ is the Wiener process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discretization\n",
    "A standard way to discretize the path integral is\n",
    "to break the time range $[0,T]$ into $n$ intervals\n",
    "\\begin{equation}\n",
    "\\tau_k=k \\cdot \\delta t, \\qquad 0\\le k\\le n,\n",
    "\\qquad n\\!: \\tau_n=T.\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "u^{(n)}(x,t)=\\int_{-\\infty}^{\\infty} \\mathcal{D}^{(n)}_{\\xi}\n",
    "\\, f\\!\\left( \\xi^{(n)}\\right) \\! \\prod_{i=0}^{n}\n",
    "e^{ -w_{i} V^{(n)}_{i} \\delta t },\n",
    "\\end{equation}\n",
    "The integration sign here denotes an $n$-dimensional integration\n",
    "over the particle steps $\\xi_k$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution \n",
    "We rewrite the process as the sequence of convolutions\n",
    "\\begin{equation}\n",
    "F^{(n)}_k(x)= \n",
    "\\sqrt{\\lambda/\\pi}\n",
    "\\int_{-\\infty}^{\\infty} \\Phi^{(n)}_{k+1}(x + \\xi)  \n",
    "\\, e^{-\\lambda \\xi^2 } d\\xi,\n",
    "\\qquad     x \\in \\mathbb{R},\n",
    "\\qquad    1\\le k \\le n,\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "\\Phi^{(n)}_{k+1}(x)= \n",
    "F^{(n)}_{k+1}(x) \\,\n",
    "e^{ -w_k V (x, \\tau_{n - k}) \\delta t  },\n",
    "\\end{equation}\n",
    "and the boundary condition\n",
    "\\begin{equation}\n",
    "F^{(n)}_{n+1}(x)=f(x),\n",
    "\\end{equation}\n",
    "the solution is expressed as follows\n",
    "\\begin{equation}\n",
    "u^{(n)}_{f}(x,T) = F^{(n)}_{1}(x) \\, e^{-w_0 V(x, T) \\, \\delta t}.\n",
    "\\end{equation}\n",
    "The iteration starts from $k=n$ and goes down to $k=1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem\n",
    "After discretization on a uniform grid, we have\n",
    "$$\n",
    "   f_{k} = \\int_{-\\infty}^{\\infty} f_{k+1}(x + y) e^{-y^2/2} dy\n",
    "$$\n",
    "If we know $f_{k+1}$ on $[-L, L]h$ and discretize convolution on $M$ points, we know the solution on a grid $[-L+M, L-M]h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inflated domain\n",
    "We start from a large domain with $L \\sim M^2$ points and then after $M$ steps find the solution at the required domain.\n",
    "\n",
    "The complexity is then $\\mathcal{O}(M^2 \\log M)$  (due to the FFT).\n",
    "\n",
    "To reduce complexity, we reshape the vector of length $M^2$ to a $M \\times M$ vector and do low-rank approximation of it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical experiment\n",
    "For numerical experiment we used diffusion equation in a weird potential which is non-periodic.\n",
    "<p>\n",
    "</p>\n",
    "<div style=\"float: left; width: 40%; margin-right: 5%; margin-bottom: 0.5em\">\n",
    "Solution (and convergence)\n",
    "<img src=\"ux2.jpg\" width=100%> \n",
    "</div>\n",
    "<div style=\"float: left; width: 40%; margin-right: 5%; margin-bottom: 0.5em\">\n",
    "Potential and initial condition\n",
    "<img src=\"vf1.jpg\" width=100%>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notes\n",
    "- We generalized it to Schrodinger equation\n",
    "- Can be generalized to $Nd$ (we inflate domain in all directions)\n",
    "- Can be applied to much more general integrals over Brownian motions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Financial integral\n",
    "<font size=6.0>\n",
    "We compute PV (Present Discounted Value) that takes into account that value of money changes in time due to basic economic parameters.\n",
    "\\begin{equation}\n",
    "PV=\\left( \\frac{\\alpha}{\\pi} \\right)^{d/2} \\int_{-\\infty}^{\\infty} \\ldots \\int_{-\\infty}^{\\infty} v(\\xi_1,\\ldots, \\xi_d)  \n",
    "\\, e^{-\\alpha \\xi_{1}^2}\\ldots e^{-\\alpha \\xi_{d}^2}\n",
    "   d\\xi_d \\ldots d\\xi_1\n",
    "\\qquad\n",
    " v(\\xi_1,\\ldots, \\xi_d) = \\sum_{k=1}^{d} u_k m_k\n",
    "\\end{equation}\n",
    "\\begin{equation*}\n",
    "u_k=\\prod_{j=0}^{k-1} \\frac{1}{1+i_j},\n",
    "\\qquad\n",
    "m_k=cr_k(1-w_k +w_k c_k),\n",
    "\\qquad\n",
    "r_k=\\prod_{j=1}^{k-1}(1-w_j),\n",
    "\\end{equation*}\n",
    "\\begin{equation}\n",
    "c_k = \\sum^{d-k}_{j=0}\\frac{1}{(1+i_0)^j}\n",
    "\\qquad\n",
    "w_k=K_1 + K_2 \\arctan(K_3 i_k + K_4),\n",
    "\\qquad\n",
    "i_k = K^{k}_0 e^{\\xi_1 + \\ldots + \\xi_k} i_0\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "Accuracy of the cross approximation $\\varepsilon = 10^{-10}$.\n",
    "Dimension of the integral is labeled by~$n$,\n",
    "It corresponds to the number of monthes in mortgage-backed security model.\n",
    "Its parameters are\n",
    "$(i_0,K_1,K_2,K_3, K_4, \\sigma^2)=(0.007,0.01, -0.005, 10, 0.5,0.0004)$.\n",
    "Ranks of the matrix are presented in column labeled by $r$.\n",
    "\n",
    " |n | r |  $T_{cross}$ (min.) |  $T_{MC}$ (min.)| \n",
    " |--|-|-----------------------|-----------------|\n",
    " |36|   7    |0.1|        7.7   | \n",
    "     |48|   10| 0.16|     11.6  | \n",
    "     |90|   10| 0.3|  21.4| \n",
    "     |180|   10| 0.5| 41.5 | \n",
    "     |360|  10| 0.8|  81.6 | \n",
    "     |720|  9| 1.56|  178| \n",
    "   |1440|  9| 2.81|  354| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solving PDEs on very fine meshes using QTT\n",
    "\n",
    "The idea of QTT can be used to solve PDEs on very fine grids. \n",
    "\n",
    "Kazeev & Schwab (2015) have proved that for all second-order elliptic/parabolic PDEs with analytic right-hand side the solution has the QTT-structure. \n",
    "\n",
    "There are hp-methods that are capable of optimal complexity, but **very difficult to be used** \n",
    "\n",
    "QTT-representation is **very simple**\n",
    "\n",
    "Let us do a demo in another window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-rectangular domains\n",
    "Recently we have realized how to use QTT for non-rectangular domains. \n",
    "\n",
    "Idea: Split into quads! (Picture taken from the paper by D. Zorin et. al), and use QTT for each particular piece.\n",
    "<img width=30% src='bommes2013qmg.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "- QTT is a very efficient and convient tool for PDE discretization on extremely fine meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graphical models\n",
    "\n",
    "A very interesting model for joint probablity distribution are **graphical models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation \n",
    "  Say we want to\n",
    "- Denoize an image $X$;\n",
    "- Generate a new image of a horse;\n",
    "- Fill the gaps (image completion).  \n",
    "\n",
    "\n",
    "To do it, we may build a probabilistic model of our images:  \n",
    "\n",
    "  $$\n",
    "  P: 256^{1000 \\times 1000} \\mapsto [0, 1]\n",
    "  $$\n",
    "  Now we can\n",
    "- Find the image that is close to $X$ and have high probability;\n",
    "- Generate new image from the distribution $P$;\n",
    "- Find the most probable values of hidden pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Three dimensions\n",
    "  Random variable $\\vec{x} = (x_1, x_2, x_3)$, $x_j \\in \\{1, 2\\}$:\n",
    "- Estimate all 8 parameters from the data:\n",
    "\n",
    "  $$\n",
    "  P(\\vec{x}) := \\frac{1}{N} \\sum_{i=1}^N [\\vec{x} = \\vec{x}^i]\n",
    "  $$\n",
    " \n",
    "- Just store it explicitly: $P \\in \\mathbb{R}^{2 \\times 2 \\times 2}$.\n",
    " \n",
    "  **Million dimensions.**  \n",
    "  \n",
    "  How to estimate and store $256^{1000 000}$ parameters (probabilities)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graphical models\n",
    "- Define an **undirected graph** $\\mathcal{G}$ with nodes corresponding to the variables (pixels of the image).\n",
    "- Define some positive functions $\\Psi_c(T_c; X, W)$ (called MRF **factors**) on the cliques of the graph $\\mathcal{G}$.\n",
    "- The model is then defined as follows:\n",
    "\t$$\n",
    "\tp(T | X, W) = 1/Z(X, W) \\prod\\limits_{c \\in \\mathcal{C}} \\Psi_c(T_c; X, W),\n",
    "\t$$\n",
    "\twhere $Z(X, W)$ is the normalization constant (statistical sum)\n",
    "\n",
    "Even if the potentials are known, $Z(X, W)$ is difficult to compute (sum of a huge array)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing marginals\n",
    "One example from the paper by [Putting MRFs on a Tensor Train, A. Novikov, A. Rodomanov, A. Osokin, D. Vetrov, ICML-2014](https://www.dropbox.com/s/d479j6zocine232/Paper.pdf)\n",
    "<img width=80% src='spinglass.svg'>\n",
    "\t\t$$\\widehat{\\mathbf{P}}(\\vec{x}) = \\prod_{i=1}^n \\exp \\left ( -\\frac{1}{T} h_i x_i \\right ) \\prod_{(i, \\, j) \\in \\mathcal{E}} \\exp \\left (-\\frac{1}{T}c_{ij} x_i x_j \\right )$$\n",
    "\n",
    "Spin glass models, $T = 1$, $c_{ij} \\sim U[-f, f]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine learning\n",
    "The set of tensors with bounded TT-ranks allows for nice approximation; i.e. it is a good idea to use it as a **regularization** for machine learning problems.\n",
    "\n",
    "This leads to the problems of the form \n",
    "\n",
    "$$F(X) \\rightarrow \\min$$\n",
    "\n",
    "where $X$ belongs to the manifold of tensors with bounded TT-ranks\n",
    "\n",
    "This can be solved using **Riemannian optimization techniques**, which seems to be very difficult, but in fact very simple and efficient (see [Manopt](www.manopt.org)).\n",
    "\n",
    "In fact, the nonlinear manifold of TT-tensors with bounded ranks has properties similar to the linear subspace!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- Tensor train decomposition is a very useful tool with many good algorithms\n",
    "- Interesting to combine with other  techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        /*width:80%;*/\n",
       "        /*margin-left:auto !important;\n",
       "        margin-right:auto;*/\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\n",
       "    h2 {\n",
       "        font-family: 'Fenix', serif;\n",
       "    }\n",
       "    h3{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "\th4{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "       }\n",
       "    h5 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\t   \n",
       "    div.text_cell_render{\n",
       "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 1.2;\n",
       "        font-size: 120%;\n",
       "        /*width:70%;*/\n",
       "        /*margin-left:auto;*/\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\";\n",
       "\t\t\tfont-size: 90%;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 50pt;\n",
       "\t\tline-height: 110%;\n",
       "        color:#CD2305;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\t\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #CD2305;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    li {\n",
       "        line-height: 110%;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
