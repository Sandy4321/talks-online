{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'start_slideshow_at': 'selected', u'theme': 'sky', u'transition': 'zoom'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.html.services.config import ConfigManager\n",
    "from IPython.utils.path import locate_profile\n",
    "cm = ConfigManager(profile_dir=locate_profile(get_ipython().profile))\n",
    "cm.update('livereveal', {\n",
    "              'theme': 'sky',\n",
    "              'transition': 'zoom',\n",
    "              'start_slideshow_at': 'selected',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Non-stationary problems and low-rank approximation of matrices and tensors\n",
    "#####Ivan Oseledets, Skolkovo Institute of Science and Technology \n",
    "##### oseledets.github.io, i.oseledets@skoltech.ru\n",
    "\n",
    "\n",
    "\n",
    "### Talk: http://github.com/oseledets/talks-online/tubingen-2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skoltech\n",
    "- Founded in 2011 as a new Western-style university near Moscow http://faculty.skoltech.ru\n",
    "- In collaboration with MIT\n",
    "- No departments: priority areas \"IT, Bio, Space and Nuclear\"\n",
    "- At the moment, 160 master students, 30 professors, 40 postdocs, 50 PhD studens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MMMA-2015\n",
    "In August 23-28 2015 we hold the **4-th Moscow conference in Matrix Methods in Mathematics and Applications**.  \n",
    "\n",
    "Confirmed speakers: C. Schwab, P. G. Martinsson, B. Benner, J. White, D. Zorin, P.-A.Absil, A. Cichocki, P. Van Dooren.\n",
    "\n",
    "**Good time to visit Moscow** (i.e., due to the exchange rate drop from 35 roubles/dollar to 55 roubles/dollar). \n",
    "\n",
    "\n",
    "\n",
    "http://matrix.inm.ras.ru/mmma-2015/\n",
    "\n",
    "<img width=30% src=\"technopark-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Talk plan\n",
    "The main goal of this talk is to show **different connections** between non-stationary problems and optimization on low-rank manifolds of matrices and tensors\n",
    "\n",
    "- **Part 1:** Low-rank approximation of the Lyapunov equation and ODEs\n",
    "- **Part 2:** Low-rank approximation and unbounded domains (\"inflation method\")\n",
    "- **Part 3:** The concept of dynamical low-rank approximation and its applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimal subspace selection for ODEs\n",
    "\n",
    "The details for this part of the talk can be found in the paper  \n",
    "[From low-rank approximation to an efficient rational Krylov subspace method for the Lyapunov equation, D. A. Kolesnikov, I. V. Oseledets](http://arxiv.org/abs/1410.3335)\n",
    "\n",
    "Consider a linear system of ODEs,\n",
    "\n",
    "$$\\frac{dy}{dt} = Ay, y(0) = y_0.$$\n",
    "\n",
    "All methods for solving such problems are based on a careful selection of a **low-dimensional subspace** $U$\n",
    "\n",
    "such that\n",
    "\n",
    "$$y(t) \\approx U c(t),$$\n",
    "\n",
    "where $U^* U = I$ and $U$ has $r$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimal subspace selection: functional\n",
    "\n",
    "The solution is given as $$y(t)  = \\exp(At) y_0,$$ \n",
    "\n",
    "assuming that $y(t) \\rightarrow 0$ when $t \\rightarrow \\infty$, the natural error measure is\n",
    "\n",
    "$$F(U) = \\int^{\\infty}_0 \\Vert y - \\widehat{y} \\Vert^2 dt, $$\n",
    "\n",
    "where $\\widehat{y} = UU^* y(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"Exact\" optimal subspace\n",
    "\n",
    "In model order reduction, the exact solution for such subspace seems to be well-known (however, we did not find exactly the same result)\n",
    "\n",
    "1. We have to solve the Lyapunov equation\n",
    "$$AX + XA^{\\top} = -y_0 y^{\\top}_0$$\n",
    "2. Compute its eigendecomposition $X = U \\Lambda U^*$, and leave $r$ leading eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem with the \"optimal solution\"\n",
    "The problem with the optimal solution is that even if $U$ is given, \n",
    "\n",
    "$$c(t) = U^* y(t)$$ \n",
    "\n",
    "is **not computable**\n",
    "\n",
    "Simple idea is to replace it with **Galerkin projection**\n",
    "\n",
    "$$c(t) \\approx \\widehat{c}(t) = e^{Bt} U^* y_0, $$\n",
    "\n",
    "where $B = U^* A U$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modified functional \n",
    "The modified functional:\n",
    "\n",
    "$$\\widetilde{y}  = U e^{Bt} U^* y_0,$$\n",
    "\n",
    "$$F(U) = \\int^{\\infty}_0 \\Vert y - \\widetilde{y} \\Vert^2 dy.$$\n",
    "\n",
    "And this functional is computable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The functional\n",
    "$\\def\\trace{\\mathop{\\mathrm{tr}}\\nolimits}$\n",
    "The functional can be written as\n",
    "\n",
    "\\begin{equation*}\n",
    "    F(U) = F_1(U) - 2 F_2(U),  \n",
    "\\end{equation*}\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "F_1(U) &= \\trace X - \\trace Z,\\\\\n",
    "F_2(U) &= \\trace U^{\\top} (P - U Z),\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "where $P$ is the solution of the Sylvester equation and $Z$ is solution of\n",
    "the Lyapunov equation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "A P + P B^{\\top} &= -y_0 c_0^{\\top},\\\\\n",
    "B Z + Z B^{\\top} &= -c_0 c_0^{\\top}.\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error estimate \n",
    "If $F(U)$ is small it gives an error bound for the Lyapunov equation:\n",
    "\n",
    " $\\Vert X - PU^* - U P^* + U Z U^* \\Vert \\leq 2 F(U)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical method\n",
    "\n",
    "**Method 1**: $U_{new} = \\begin{bmatrix} U & P - UZ \\end{bmatrix}$,\n",
    "\n",
    "double the size of the basis at each step.\n",
    "\n",
    "**Method 2**: We found that effectively the basis is expanded by only $1-2$ vectors, and based on this we obtained a **very simple** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ALR method\n",
    "\n",
    "At each step we add to the basis $U$ two vectors:\n",
    "\n",
    "1. A next Krylov vector $w_k$ \n",
    "2. Next rational Krylov vector $v_k = (A + s I)^{-1} w_k$, where $s = q^* A q$, \n",
    "  and $q$ is the **normalized last row** of the matrix $Z$ that solves\n",
    "  $$BZ + Z B^* = c_0 c^*_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Existing approaches\n",
    "We ended up with Rational-Krylov-type method (there are many others), \n",
    "\n",
    "1. KPIK (Knizhnermann, Druskin, Simoncini) - $A$ and $A^{-1}$ subspaces\n",
    "2. RKSM (Druskin, Simoncini) - optimize the shifts to minimize the spectral error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main difference to RKSM\n",
    "The shifts generated by ALR are contained in the numerical range of $B$, not $A$, and are much less **spread**, but the convergence is **not worse** then for RKSM.\n",
    "\n",
    "<img width=100% src=\"test.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Future work\n",
    "We are working on the convergence estimates for ALR, but they are not clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2\n",
    "\n",
    "Now we go to the next part of the talk: diffusion/Schrodinger equation in **unbounded domains** using \"inflation\" method with low-rank approximation.\n",
    "\n",
    "It is based on the joint work with my postdoc [Mikhail Litsarev](http://oseledets.github.io/people/litsarev/)\n",
    "\n",
    "The idea is described in the paper\n",
    "[Low-rank approach to the computation of path integrals](http://arxiv.org/abs/1504.06149)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unbounded domains\n",
    "\n",
    "I will illustrate the idea on the Schroedinger equation. \n",
    "\\begin{equation}\n",
    "i \\frac{\\partial }{\\partial t } \\psi(x, t )=\n",
    "\\left (  -\\frac{1}{2} \\nabla^2+ V(x)  \\right) \\psi(x, t ), \\quad \\psi(x, 0) = \\psi^{(0)}(x).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Discretization on an infinite grid\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial t} \\psi_k(t) =  i \\frac{\\psi_{k-1}(t) - 2 \\psi_k(t) + \\psi_{k+1}(t)}{2h^2} + V(x_k) \\psi_k(t), \\quad \\psi_k(0) = \\psi^{(0)}(x_k), \\quad x_k = k h, \\quad k  \\in \\mathbb{Z}. \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix form\n",
    "\\begin{equation}\n",
    "\\left \\{\n",
    "\\begin{split}\n",
    "&\\frac{d}{d t} \\mathbf{\\psi} (t)=\n",
    "\\mathbf{i}\\, \\mathbf{H} \\, \\mathbf{\\psi} (t), \\\\\n",
    "&\\mathbf{\\psi}(0) = \\mathbf{\\psi}_0,\n",
    "\\end{split}\n",
    "\\right.\n",
    "\\qquad\n",
    "\\mathbf{H}=\\mathbf{K}+\\mathbf{V},\n",
    "\\end{equation}\n",
    "\n",
    "The matrix $\\mathbf{K}$ is a bi-infinite tridiagonal symmetric Toeplitz matrix with elements\n",
    "$$K_{kl} = \\mathbf{k}_{k-l}, $$\n",
    "wher $\\mathbf{k}_0 = -\\frac{2}{h^2}$, $\\mathbf{k}_1 = \\mathbf{k}_{-1} = \\frac{1}{h^2}$ and all other elements of $\\mathbf{k}$ are equal to $0$. The operator $\\mathbf{V}$            \n",
    "corresponds to a bi-infinite diagonal matrix with elements $V(x_k)$ on the diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting scheme\n",
    "Now we apply the second-order Marchuk-Strang splitting\n",
    "\n",
    "$$\\psi(t + \\tau) = e^{i \\mathbf{H} \\tau} \\psi(t) = e^{i \\mathbf{V} \\tau/2} e^{i \\mathbf{K} \\tau} e^{i \\mathbf{V} \\tau/2} \\psi(t) + \\mathcal{O}(\\tau^3).$$\n",
    "\n",
    "Since matrix $\\mathbf{V}$ is a diagonal matrix, its exponent is also a diagonal matrix.  The most interesting part is\n",
    "the computation of the action of the matrix exponent\n",
    "\n",
    "\\begin{equation}\n",
    "\\widehat{\\varphi} = e^{i \\mathbf{K} \\tau} \\varphi. \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exponent of an infinite Laplacian\n",
    "Since the matrix $\\mathbf{K}$ is a Toeplitz matrix, the exponent is also a Toeplitz matrix, and the action of the operator is\n",
    "a **convolution**\n",
    "$$\\widehat{\\varphi}_k = \\sum_{l=-\\infty}^{\\infty} \\mathbf{b}_{l} \\varphi_{l+k}.$$\n",
    "\n",
    "The coefficients $b_l$ depend on $\\tau$ and $h$.\n",
    "\n",
    "**Theorem**: $b_l$ are exponentially decaying for $|l| > M$, $M  \\sim \\frac{\\tau}{h^2}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo\n",
    "Now the short demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mx =  603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1149a8f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104899910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.fft import fft, ifft\n",
    "Nx = 200\n",
    "Mx = 3 * Nx + 3\n",
    "hx = 1.0/Nx\n",
    "tau = hx\n",
    "print 'Mx = ', Mx\n",
    "H = np.zeros(Mx)\n",
    "H[0] = -2\n",
    "H[1] = 1\n",
    "H[Mx - 1] = 1\n",
    "cf = 0.5 * tau / (hx ** 2)\n",
    "H = -cf * H\n",
    "lam_analytic = fft(H)\n",
    "band = ifft(np.exp(-1j * lam_analytic))\n",
    "abs_band = abs(band)\n",
    "plt.semilogy(abs_band)\n",
    "plt.title('Convolution coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main idea: inflation method\n",
    "We can replace the infinite convolution by a window one!\n",
    "\n",
    "$$\\widehat{\\varphi}_k \\approx \\sum_{l=-M/2}^{M/2} \\mathbf{b}_{l} \\varphi_{k+l}.$$\n",
    "\n",
    "Thus, if we know the solution at $[-L, L]$, we can compute it for $[-L+M/2, L-M/2]$ (smaller interval).\n",
    "\n",
    "How big $L$ should be? \n",
    "\n",
    "$\\tau \\sim h$, $M \\sim \\frac{1}{h}$, thus to get time $T$ we need at least $MT$ steps. \n",
    "\n",
    "At each step $M$ points disappear, thus $L \\sim TM^2$ points are needed (**inflated domain**).\n",
    "\n",
    "How to break the complexity/storage problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use low-rank!\n",
    "\n",
    "1. Take the grid uniform $x_k$ with $K M$ points, values of $f$ on this grid \n",
    "and **reshape it into $K \\times M$ matrix.**\n",
    "2. Approximate it by rank-$r$ matrix.\n",
    "\n",
    "**Theorem** After one convolution the rank is at most $2r$ (thus we approximate).\n",
    "\n",
    "Intialization and multiplication by $e^{i V \\tau}$ is done **cross approximation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical experiment\n",
    "For numerical experiment we used diffusion equation in a weird potential which is non-periodic.\n",
    "<p>\n",
    "</p>\n",
    "<div style=\"float: left; width: 40%; margin-right: 5%; margin-bottom: 0.5em\">\n",
    "Solution (and convergence)\n",
    "<img src=\"ux2.jpg\" width=100%> \n",
    "</div>\n",
    "<div style=\"float: left; width: 40%; margin-right: 5%; margin-bottom: 0.5em\">\n",
    "Potential and initial condition\n",
    "<img src=\"vf1.jpg\" width=100%>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "- Inflated domain allows us to accurately compute solution without artificial boundaries\n",
    "- Experimentally verified low-rank structure\n",
    "- Easy to  extend to other types of problems (2D, 3D, wave equations)\n",
    "- Theory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 3\n",
    "\n",
    "Why we need dynamical low-rank approximation (with an application)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Low-rank approximation of matrices\n",
    "\n",
    "Given a matrix $A$ its **low-rank approximation** can be parametrized by the product $UV^{\\top}$.\n",
    "\n",
    "\n",
    "$$A \\approx UV^{\\top}, $$\n",
    "\n",
    "where $U$ is $n \\times r$ and $V$ is $m \\times r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing low-rank factorization\n",
    "\n",
    "Minimization of \n",
    "$$\\min_{\\mathrm{rank}(A_r)=r}\\Vert A - A_r \\Vert_2 = \\sigma_{r+1}$$\n",
    "\n",
    "can be done by the singular value decomposition (SVD).\n",
    "\n",
    "Or by **sampling** and **cross approximation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Function approximation\n",
    "\n",
    "In the function approximation, low-rank approximation is equivalent to the **separation of variables**  \n",
    "\n",
    "\n",
    "$$f(x_1, \\ldots, x_d) \\approx \\sum_{\\alpha=1}^r U_1(x_1, \\alpha) \\ldots U_d(x_d, \\alpha),$$\n",
    "\n",
    "Often is better to use **stable** tensor formats (TT-format, HT-format).\n",
    "\n",
    "The main problem is to select **right variables** that **can be separated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A typical setup\n",
    "\n",
    "Recommender system: we have a **user-product matrix**, and we want to fill the missing entries.\n",
    "\n",
    "We solve **matrix completion** problem:\n",
    "\n",
    "$$\\Vert W \\circ (A - B) \\Vert \\rightarrow \\min$$\n",
    "\n",
    "But the accuracy is then measured using only the sign of the approximation! (sign-rank problem!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General principle\n",
    "\n",
    "It means, you have to use **absolutely different** functional (not quadratic, not matrix completion) in the minimization problem.\n",
    "\n",
    "For a sign-rank, a good surrogate is the **logistic loss**\n",
    "\n",
    "$$l(x, y) = \\log(1 + e^{-(2y - 1)x}) $$\n",
    "\n",
    "$$F(X, Y)  = \\sum_{ij} l(x_{ij}, y_{ij})$$\n",
    "\n",
    "Then we minimize $F(X, Y)$ given $Y$ subject to low-rank constraints on $X$.\n",
    "\n",
    "\n",
    "**Non-quadratic functional** -- forget about **alternating least squares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Riemannian optimization\n",
    "\n",
    "One of the most important properties of low-rank formats is the structure of the **tangent space**\n",
    "\n",
    "Given $A = U S V^{\\top}$, with orthonormal $U$ and $V$ the tangent space is defined as\n",
    "\n",
    "$$Z = U S V^{\\top} + \\delta U S V^{\\top} + U \\delta S V^{\\top} + U S \\delta V^{\\top},$$\n",
    "\n",
    "subject to $$\\delta U^{\\top} U + U^{\\top} \\delta U = \\delta V^{\\top} V + V^{\\top} \\delta V = 0$$\n",
    "\n",
    "The projector onto the tangent space is given by \n",
    "\n",
    "$$P_T(Z) = Z - (I - UU^{\\top}) Z (I - VV^{\\top})$$\n",
    "\n",
    "We can write down the projector for TT/HT formats as well!\n",
    "\n",
    "Given the projector, you can solve the problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization methods on manifolds\n",
    "\n",
    "For the low-rank manifold (matrix, TT, HT) we can efficiently compute the **projection** to the tangent space.\n",
    "\n",
    "\n",
    "The simplest is to **project the gradient onto the tangent space:**\n",
    "\n",
    "$$x_{k+1} = R(x_k + P_{\\mathcal{T}}(\\nabla F)), $$\n",
    "\n",
    "where $R$ is the mapping from the tangent space to the manifold, called **retraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "- Use the functional you want to minimize, not quadratic loss\n",
    "- Try the Riemannian gradient descent first: simple to use, often converges well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Tensors \n",
    "\n",
    "- The most challenging problems are problems with **tensors** (curse of dimensionality, tricky optimization questions).\n",
    "\n",
    "- There are **tensor formats** that are **matrix low-rank approximation manifolds** in disguise\n",
    "\n",
    "- We can use efficient matrix techniques for working with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensor-train  format\n",
    "\n",
    "The simplest SVD-based format is the **tensor-train format**\n",
    "\n",
    "$$A(i_1, \\ldots, i_d) = G_1(i_1) \\ldots G_d(i_d),$$\n",
    "\n",
    "i.e. the **product of matrices, depending only on 1 index**, $G_k(i_k)$ is $r_{k-1} \\times r_k$ and $r_0 = r_d = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Canonical format\n",
    "\n",
    "A popular choice in function approximation is the **canonical** or sum-of-products format\n",
    "\n",
    "$$A(i_1, \\ldots, i_d) \\approx \\sum_{\\alpha=1}^r U_1(i_1, \\alpha) \\ldots U_d(i_d, \\alpha),$$\n",
    "\n",
    "i.e. sum of separable functions.\n",
    "\n",
    "Disadvantage: **it is not a stable format**: the best approximation may not exist, and may be hard to compute if we know that it exists!\n",
    "\n",
    "However, for a particular tensor $A$ **it can be very efficient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensor train\n",
    "The TT-format \n",
    "\n",
    "$$A(i_1, \\ldots, i_d) = G_1(i_1) \\ldots G_d(i_d),$$\n",
    "\n",
    "can be characterized by the following condition:\n",
    "\n",
    "$$\\mathrm{rank}(A_k) = r_k,$$\n",
    "\n",
    "where $A_k = A(i_1 i_2 \\ldots i_k; i_{k+1} \\ldots i_d)$ is the **k-th unfolding** of the tensor.\n",
    "\n",
    "I.e. it is the **intersection of low-rank matrix manifolds**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Software\n",
    "We have a TT-Toolbox, both in MATLAB http://github.com/oseledets/TT-Toolbox and in Python http://github.com/oseledets/ttpy \n",
    "- Computing the TT representation (i.e. checking if there is such a representation)\n",
    "- Performing basic operations\n",
    "- Adaptive sampling algorithms (cross approximation)\n",
    "- Optimization algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization over TT-manifold\n",
    "\n",
    "Given $A(i_1, \\ldots, i_d) = G_1(i_1) \\ldots G_d(i_d)$ optimize over one core $G_k(i_k)$.  \n",
    "\n",
    "- Good for **quadratic functionals**, and also you can parametrize     \n",
    "    \n",
    "    $$\\mathrm{vec}(A) = Q \\mathrm{vec}(G_k),$$  \n",
    "    where $Q$ is orthonormal.\n",
    "- Bad for non-quadratic (frequent in machine learning!)\n",
    "\n",
    "Therefore, Riemanian optimization techniques are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Riemannian gradient descent\n",
    "\n",
    "$$x_{k+1} = R(x_k + \\alpha_k P_{\\mathcal{T}}(\\nabla F)), $$\n",
    "\n",
    "The retraction step is easy, since the projection alwas has rank $2r$, so it can be done by **rounding**.\n",
    "\n",
    "The main problem is the computation of $$P_{\\mathcal{T}}(\\nabla F)$$ without exponential complexity.\n",
    "\n",
    "If it is possible, this is the way to go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: all-subsets regression\n",
    "\n",
    "Consider the **binary classification problem**. \n",
    "\n",
    "Log-regression is the simplest choice: given the **feature vector** $x$, \n",
    "\n",
    "we predict the probability to observe $y_i$\n",
    "\n",
    "$$p = Z \\exp(-y_i \\langle w, x_i \\rangle).$$\n",
    "\n",
    "I.e. the predictor variable is just the linear combination of the components of the feature vector,\n",
    "\n",
    "and $w$ is the **weight vector**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## All-subsets regression\n",
    "\n",
    "We can use other predictor variables, for example, select product of features (subsets) like\n",
    "\n",
    "$$w_1 x_1 + w_{125} x_1 x_2 x_5 + \\ldots $$\n",
    "\n",
    "We can code all **possible subsets** in this form by a vector of length $2^d$, or tensor of size $2 \\times \\ldots \\times 2$.\n",
    "\n",
    "(i.e. if there is $x_1$ in the term, or not). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The predictor variable is then **$t = \\langle W, X \\rangle$**, where $\\langle \\cdot \\rangle$ is the scalar product of tensors.\n",
    "\n",
    "$W$ is $2 \\times 2 \\times \\ldots \\times 2$ -- **weight tensor**\n",
    "\n",
    "We impose low-rank constraints on the $W$, to avoid **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization problem\n",
    "The total loss is the sum of individual losses\n",
    "$$F(W) = \\sum_{k=1}^K f(y_i, \\langle X_i, W \\rangle),$$\n",
    "\n",
    "where $X_i$ is the low-rank tensor obtained from the **feature vector** $x_i$.\n",
    "\n",
    "The gradient is easily computatble:\n",
    "\n",
    "$$\\nabla F = \\sum_{k=1}^K \\frac{df}{dz}(y_i, \\langle X_i, W \\rangle) X_i,$$\n",
    "\n",
    "and **projection** onto the tangent space can be computed in a fast way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminary results\n",
    "On the problem [Otto](https://www.kaggle.com/c/otto-group-product-classification-challenge) from Kaggle, the larger the rank, the better is learning \n",
    "<img src='all-subsets.svg'>\n",
    "\n",
    "You have to train fast   \n",
    "(GPU implementation is necessary, as in the Deep Learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Low-rank factorization as initialization\n",
    "\n",
    "You can use low-rank factorization to initialize other optimization methods.\n",
    "\n",
    "We have successfully speeded up the convolutional neural networks by factorizing a 4D tensor into the canonical format and then **fine-tuning it**.\n",
    "\n",
    "Thanks to the wonderful TensorLab toolbox by L. De Lathauwer!\n",
    "\n",
    "[Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition\n",
    "Vadim Lebedev, Yaroslav Ganin, Maksim Rakhuba, Ivan Oseledets, Victor Lempitsky,  ICLR 2015](http://arxiv.org/abs/1412.6553)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Publications and software\n",
    "- http://oseledets.github.io -- Scientific Computing Group at Skoltech\n",
    "- http://github.com/oseledets/TT-Toolbox -- Tensor Trains in MATLAB\n",
    "- http://github.com/oseledets/ttpy -- Tensor Trains in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        /*width:80%;*/\n",
       "        /*margin-left:auto !important;\n",
       "        margin-right:auto;*/\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\n",
       "    h2 {\n",
       "        font-family: 'Fenix', serif;\n",
       "    }\n",
       "    h3{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "\th4{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "       }\n",
       "    h5 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\t   \n",
       "    div.text_cell_render{\n",
       "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 1.2;\n",
       "        font-size: 120%;\n",
       "        /*width:70%;*/\n",
       "        /*margin-left:auto;*/\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\";\n",
       "\t\t\tfont-size: 90%;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 50pt;\n",
       "\t\tline-height: 110%;\n",
       "        color:#CD2305;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\t\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #CD2305;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    li {\n",
       "        line-height: 110%;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
